{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple examples of ensembling models\n",
    "\n",
    "Expected that hyperparameters of base models are already tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHIFT = 190\n",
    "os.environ['LIGHTGBM_EXEC'] = '/home/eamag/apps/LightGBM'  # path to LightGBM executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/eamag/data/allstate/train.csv.zip'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-07a7520b1e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/data/allstate/train.csv.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eamag/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eamag/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eamag/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eamag/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eamag/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/eamag/data/allstate/train.csv.zip'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df = pd.read_csv('~/data/allstate/train.csv.zip', compression='zip')\n",
    "\n",
    "for column in tqdm(df.columns):\n",
    "    encoder = LabelEncoder()\n",
    "    if column.startswith('cat') :\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "        df['{}_sz'.format(column)] = df[column].map(df.groupby(column).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For speed and simplicity there are only one split 80% / 20%\n",
    "This is equivalent to a single iteration of 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state = 0)\n",
    "y_train, y_test = train['loss'], test['loss']\n",
    "del train['loss'], test['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit simple XGBoost and LightGBM models (without any tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162.57690445\n",
      "CPU times: user 4min 55s, sys: 1.35 s, total: 4min 56s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(train, label=np.log(y_train + SHIFT))\n",
    "dtest = xgb.DMatrix(test)\n",
    "params = {'silent': 1}\n",
    "model = xgb.train(params, dtrain, 100)\n",
    "y_pred_1 = np.exp(model.predict(dtest)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150.66772131\n",
      "CPU times: user 27 s, sys: 1.21 s, total: 28.2 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pylightgbm.models import GBMRegressor\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(train, np.log(y_train + SHIFT))\n",
    "y_pred_2 = np.exp(clf.predict(test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get mean of this predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147.67752573\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_1 + y_pred_2)/2\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to choose weights for convex combination of predictions\n",
    "i.e the sum of the weights is equal to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1149.49742146\n",
      "0.1 1148.50355639\n",
      "0.15 1147.7101578\n",
      "0.2 1147.12598108\n",
      "0.25 1146.74645865\n",
      "0.3 1146.56618344\n",
      "0.35 1146.57364663\n",
      "0.4 1146.76553844\n",
      "0.45 1147.12663828\n",
      "0.5 1147.67752573\n",
      "0.55 1148.38881233\n",
      "0.6 1149.24503975\n",
      "0.65 1150.28968449\n",
      "0.7 1151.50808495\n",
      "0.75 1152.90743673\n",
      "0.8 1154.48431484\n",
      "0.85 1156.22900358\n",
      "0.9 1158.16242752\n",
      "0.95 1160.28705474\n",
      "----------------\n",
      "best: 0.3 1146.56618344\n"
     ]
    }
   ],
   "source": [
    "best_a = None\n",
    "min_err = 10**6\n",
    "for a in np.arange(.05, 1, .05):\n",
    "    y_pred = a*y_pred_1 + (1 - a)*y_pred_2\n",
    "    err = mean_absolute_error(y_pred, y_test)\n",
    "    if err < min_err:\n",
    "        min_err = err\n",
    "        best_a = a\n",
    "    print(a, err)\n",
    "print('----------------')\n",
    "print('best:', best_a, min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is better than simple mean.\n",
    "\n",
    "When using such method better models will have larger weight. This can be a problem if you have models with different quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get out of fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from pylightgbm.models import GBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "def get_xgb_pred(X_train, X_test, y_train, params=None, n_trees=100, res_transform=None):\n",
    "    if params is None:\n",
    "        params = {'silent': 1}\n",
    "    if res_transform is None:\n",
    "        res_transform = lambda x: x\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, n_trees)\n",
    "    return res_transform(model.predict(dtest))\n",
    "\n",
    "def get_lightgbm_pred(X_train, X_test, y_train, params=None, n_trees=100, res_transform=None):\n",
    "    if params is None:\n",
    "        params = {'verbose': False}\n",
    "    if not 'num_iterations' in params:\n",
    "        params['num_iterations'] = n_trees\n",
    "    if res_transform is None:\n",
    "        res_transform = lambda x: x\n",
    "    clf = GBMRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return res_transform(clf.predict(X_test))\n",
    "\n",
    "def predict_outoffolds(X, y, X_test=None, func='get_xgb_pred', params=None, res_transform=None, n_splits=3):\n",
    "    if X_test is None:\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        y_pred = np.zeros_like(y.values)\n",
    "        for train_inds, test_inds in kf.split(X):\n",
    "            y_pred[test_inds] = globals()[func](X.iloc[train_inds], X.iloc[test_inds],\n",
    "                                                y.iloc[train_inds], res_transform=res_transform, params=params)\n",
    "        return y_pred\n",
    "    else:\n",
    "        return globals()[func](X, X_test, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stack = pd.DataFrame(index=train.index)\n",
    "test_stack = pd.DataFrame(index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 28s, sys: 7.19 s, total: 15min 35s\n",
      "Wall time: 7min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_stack['y_xgb'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_xgb_pred')\n",
    "test_stack['y_xgb'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_xgb_pred')\n",
    "train_stack['y_lightgbm'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_lightgbm_pred')\n",
    "test_stack['y_lightgbm'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_lightgbm_pred')\n",
    "train_stack['y_xgb'] = np.exp(train_stack.y_xgb) - SHIFT\n",
    "test_stack['y_xgb'] = np.exp(test_stack.y_xgb) - SHIFT\n",
    "train_stack['y_lightgbm'] = np.exp(train_stack.y_lightgbm) - SHIFT\n",
    "test_stack['y_lightgbm'] = np.exp(test_stack.y_lightgbm) - SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168.72252642 1149.25187965 1162.57690445 1150.66772131\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(train_stack.y_xgb.fillna(0), y_train),\n",
    "      mean_absolute_error(train_stack.y_lightgbm.fillna(0), y_train),\n",
    "      mean_absolute_error(test_stack.y_xgb.fillna(0), y_test),\n",
    "      mean_absolute_error(test_stack.y_lightgbm.fillna(0), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit linear regression without bias on this two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166.50388063\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(train_stack[['y_xgb', 'y_lightgbm']], y_train)\n",
    "y_pred = lr.predict(test_stack[['y_xgb', 'y_lightgbm']])\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.420327063731 0.693043542054\n"
     ]
    }
   ],
   "source": [
    "print(*lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit nonlinear model on second level\n",
    "concatenate meta features with original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train = pd.concat([train, train_stack], axis=1)\n",
    "_test = pd.concat([test, test_stack], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145.20823757\n",
      "CPU times: user 25.7 s, sys: 1.18 s, total: 26.9 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pylightgbm.models import GBMRegressor\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(_train, np.log(y_train + SHIFT))\n",
    "y_pred = np.exp(clf.predict(_test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better than convex combination of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to add yet another LightGBM\n",
    "parameters are intentionally set to non-optimal values to get a weaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164.09046584\n",
      "CPU times: user 25.2 s, sys: 1.18 s, total: 26.3 s\n",
      "Wall time: 54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    'num_iterations': 100,\n",
    "    'num_leaves': 127,\n",
    "    'feature_fraction': .5,\n",
    "    'bagging_fraction': .5,\n",
    "    'learning_rate': .06,\n",
    "    'min_data_in_leaf': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "from pylightgbm.models import GBMRegressor\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(train, np.log(y_train + SHIFT))\n",
    "y_pred_3 = np.exp(clf.predict(test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148.42467693\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_1 + y_pred_2 + y_pred_3)/3\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weak model worsened the result of averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convex combination of predictions tuned by Sequential Least Squares Programming solver\n",
    "https://github.com/jdwittenauer/kaggle/blob/master/OttoGroup/find_ensemble_weights.py\n",
    "\n",
    "http://stackoverflow.com/questions/35631192/element-wise-constraints-in-scipy-optimize-minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def log_loss_func(weights):\n",
    "    \"\"\"\n",
    "    scipy minimize will pass the weights as a numpy array\n",
    "    \"\"\"\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, preds):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_absolute_error(y_test, final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = [y_pred_1, y_pred_2, y_pred_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_weights = np.ones(len(preds)) / len(preds)\n",
    "# adding constraints\n",
    "cons = ({'type': 'eq', 'fun': lambda w: 1-sum(w)})  # weights are sum to 1\n",
    "bounds = [(0, 1)] * len(preds)  # and bounded between 0 and 1\n",
    "w = minimize(log_loss_func, init_weights, method='SLSQP', bounds=bounds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30029172,  0.46381807,  0.23589021])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147.4365723451813"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.dot(w.x.reshape(1, -1), np.vstack([y_pred_1, y_pred_2, y_pred_3])).ravel(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than simple mean, but it is not the general case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get out-of-fold prediction for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 4.3 s, total: 1min 31s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_stack['y_lightgbm2'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_lightgbm_pred', params=params)\n",
    "test_stack['y_lightgbm2'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_lightgbm_pred',\n",
    "                                               params=params)\n",
    "train_stack['y_lightgbm2'] = np.exp(train_stack.y_lightgbm2) - SHIFT\n",
    "test_stack['y_lightgbm2'] = np.exp(test_stack.y_lightgbm2) - SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158.32348978 1150.66772131\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(train_stack.y_lightgbm2.fillna(0), y_train),\n",
    "      mean_absolute_error(test_stack.y_lightgbm2.fillna(0), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit nonlinear model on second level\n",
    "concatenate meta features with original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_train = pd.concat([train, train_stack], axis=1)\n",
    "_test = pd.concat([test, test_stack], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144.95280688\n",
      "CPU times: user 31.5 s, sys: 1.46 s, total: 33 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'verbose': False, 'num_iterations': 100, 'num_leaves': 63}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(_train, np.log(y_train + SHIFT), test_data=[(_test, np.log(y_test + SHIFT))])\n",
    "y_pred = np.exp(clf.predict(_test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some links\n",
    "http://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity/forums/t/25743/stacking-understanding-python-package-for-stacking\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity/forums/t/25240/weights-in-an-ensemble"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}